How to create EKS(Elastic Kubernetes service) cluster in AWS using eksctl tool
******************************************************************************

AWS CLI Setup
*************

1. sudo apt update -y

2. curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"

3. sudo apt install unzip

4. unzip awscliv2.zip

5. sudo ./aws/install

	it shows --> You can now run: /usr/local/bin/aws --version

6. aws --version 

	used to show version --> aws-cli/2.28.1 Python/3.13.4 Linux/6.8.0-1029-aws exe/x86_64.ubuntu.24

7. aws configure
	AWS Access Key ID [None]:
	AWS Secret Access Key [None]:
	Default region name [None]: ap-southeast-1a
	Default output format [None]: json


Install eksctl
**************

8. curl --silent --location "https://github.com/eksctl-io/eksctl/releases/latest/download/eksctl_Linux_amd64.tar.gz" | tar xz -C /tmp

9. sudo mv /tmp/eksctl /usr/local/bin

10. eksctl version --> used to see the version


Install kubectl
***************

11. curl -LO "https://dl.k8s.io/release/v1.30.1/bin/linux/amd64/kubectl"

12. chmod +x kubectl

13. sudo mv kubectl /usr/local/bin/

14. kubectl version --client --> used to see the version


Create EKS Cluster
******************


15. eksctl create cluster --name my-cluster --region ap-southeast-1 --zones ap-southeast-1a,ap-southeast-1b --nodegroup-name my-nodes --node-type t2.medium --nodes 2 --nodes-min 1 --nodes-max 3 --managed

Verify Cluster
**************

16. aws eks update-kubeconfig --region ap-south-1 --name my-cluster

17. kubectl get nodes

18. kubectl get svc

19. kubectl get pods --all-namespaces


To delete
*********

20. eksctl delete cluster --name my-cluster --region ap-southeast-1

21. aws cloudformation delete-stack --stack-name eksctl-my-cluster-cluster --region ap-southeast-1



eksctl create cluster --name my-cluster --region ap-south-1 --zones ap-south-1a,ap-south-1b --nodegroup-name my-nodes --node-type c7i-flex.large --nodes 2 --nodes-min 1 --nodes-max 3 --managed
